import pandas as pd
import numpy as np
import os
import traceback
from collections import defaultdict
import tkinter as tk
from tkinter import filedialog, messagebox, scrolledtext
import sys
from io import StringIO

class TextRedirector:
    def __init__(self, widget):
        self.widget = widget
        self.widget.configure(state='disabled')

    def write(self, text):
        self.widget.configure(state='normal')
        self.widget.insert(tk.END, text)
        self.widget.configure(state='disabled')
        self.widget.see(tk.END)
        self.widget.update()

    def flush(self):
        pass

def processar_formulas(df, nivel_1_codes, batch_size=10, max_levels=10, log_widget=None):
    def log(message):
        print(message)
        if log_widget:
            log_widget.write(message + "\n")

    try:
        # Validar colunas obrigatórias
        required_columns = ["CODIGO", "NIVEL", "QUANTIDADE", "AUXILIAR"]
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            raise ValueError(f"Colunas ausentes em Totvs_Formulas: {', '.join(missing_cols)}")
        if df.empty:
            raise ValueError("A planilha Totvs_Formulas está vazia.")
        if not nivel_1_codes:
            raise ValueError("A lista de Nivel_1 está vazia.")

        # Validar formato da coluna AUXILIAR
        df["AUXILIAR"] = df["AUXILIAR"].astype(str).str.strip().str.upper()
        invalid_auxiliar = df[~df["AUXILIAR"].str.match(r'^[A-Z0-9]+[PC]$')]
        if not invalid_auxiliar.empty:
            log(f"Aviso: {len(invalid_auxiliar)} linhas com AUXILIAR inválido:")
            log(invalid_auxiliar[["CODIGO", "AUXILIAR"]].head().to_string())
            df = df[df["AUXILIAR"].str.match(r'^[A-Z0-9]+[PC]$')]

        # Log inicial dos dados lidos
        log(f"Dados lidos da planilha Totvs_Formulas: {df.shape[0]} linhas, {df.shape[1]} colunas")
        log(f"Primeiras linhas:\n{df.head().to_string()}")
        log(f"Produtos de Nivel_1 fornecidos: {len(nivel_1_codes)}")
        log(f"Exemplos de Nivel_1: {nivel_1_codes[:5]}")

        # Pré-processamento: Mapear níveis mínimos de explosão e descrições
        log("Pré-processando dependências...")
        dependency_map = defaultdict(lambda: float('inf'))  # Código -> nível mínimo
        description_map = {}  # Código -> descrição

        def calculate_min_levels(df, codigo, current_level=0, seen_codes=None):
            if seen_codes is None:
                seen_codes = set()
            if codigo in seen_codes:
                log(f"Aviso: Ciclo detectado para CODIGO={codigo}")
                return
            seen_codes.add(codigo)
            components = df[df["Parent"] == codigo]
            # Log para monitorar componentes de PI1031
            if codigo == "PI1031":
                log(f"Processando PI1031: {len(components)} componentes encontrados")
            for _, row in components.iterrows():
                comp_code = row["CODIGO"]
                comp_auxiliar = row["AUXILIAR"]
                # Ignorar linhas com AUXILIAR terminando em 'P'
                if comp_auxiliar.endswith("P"):
                    continue
                qty = pd.to_numeric(row["QUANTIDADE"], errors="coerce")
                desc = row.get("DESCRICAO", comp_code)  # Usar DESCRICAO ou CODIGO se ausente
                description_map[comp_code] = desc
                dependency_map[comp_code] = min(dependency_map[comp_code], current_level + 1)
                calculate_min_levels(df, comp_code, current_level + 1, seen_codes.copy())

        # Criar coluna Parent temporária usando AUXILIAR
        df["Parent"] = df.apply(
            lambda row: row["CODIGO"] if row["AUXILIAR"].endswith("P") else np.nan, axis=1
        )
        df["Parent"] = df["Parent"].ffill()

        # Normalizar CODIGO para evitar duplicatas por formatação
        df["CODIGO"] = df["CODIGO"].str.strip().str.upper()

        # Calcular níveis mínimos e descrições apenas para Nivel_1
        top_level = [code for code in nivel_1_codes if code in df[df["AUXILIAR"].str.endswith("P")]["CODIGO"].values]
        if not top_level:
            raise ValueError("Nenhum código de Nivel_1 encontrado em Totvs_Formulas com AUXILIAR='P'.")
        for codigo in top_level:
            desc = df[df["CODIGO"] == codigo]["DESCRICAO"].iloc[0] if "DESCRICAO" in df.columns else codigo
            description_map[codigo] = desc
            calculate_min_levels(df, codigo)
        log(f"Dependências mapeadas: {len(dependency_map)} códigos")
        log(f"Exemplo de dependency_map: {dict(list(dependency_map.items())[:10])}")
        log(f"Exemplo de description_map: {dict(list(description_map.items())[:10])}")

        # Exportar dependency_map para inspeção
        dependency_data = [{"Codigo": k, "Nivel_Minimo": v} for k, v in dependency_map.items()]
        pd.DataFrame(dependency_data).to_csv("dependency_map.csv", index=False)
        log("Exportado dependency_map.csv")

        # Relatório de códigos com muitos componentes
        component_counts = df[df["AUXILIAR"].str.endswith("C")].groupby("Parent")["CODIGO"].count()
        suspicious_codes = [{"Codigo": k, "Num_Componentes": v} for k, v in component_counts.items() if v > 20]
        pd.DataFrame(suspicious_codes).to_csv("suspicious_codes.csv", index=False)
        log(f"Exportado suspicious_codes.csv com {len(suspicious_codes)} códigos com mais de 20 componentes")

        def normalize_qty(df, parent, qty_col="QUANTIDADE"):
            try:
                df[qty_col] = pd.to_numeric(df[qty_col], errors="coerce")
                components = df[df["Parent"] == parent]
                if components.empty:
                    log(f"Aviso: Nenhum componente encontrado para Parent={parent}")
                    return pd.Series(np.nan, index=df.index)
                # Normalizar apenas para produtos que começam com "PI"
                if parent.startswith("PI"):
                    total_qty = components[qty_col].sum()
                    if pd.isna(total_qty) or total_qty <= 1.1:
                        log(f"Aviso: Normalização não aplicada para {parent} (soma={total_qty})")
                        return components[qty_col]
                    log(f"Normalizando quantidades para {parent} (soma={total_qty})")
                    return components[qty_col] / total_qty
                # Retornar quantidades originais para produtos que não começam com "PI"
                log(f"Quantidades mantidas para {parent} (não começa com PI)")
                return components[qty_col]
            except Exception as e:
                raise ValueError(f"Erro ao normalizar quantidades para parent {parent}: {str(e)}")

        def build_hierarchy(df, codigo, description_map, nivel=1, parent_path=None, seen_codes=None, exploded_codes=None):
            if parent_path is None:
                parent_path = [codigo]
            if seen_codes is None:
                seen_codes = set()
            if exploded_codes is None:
                exploded_codes = set()
            if nivel > max_levels:
                return []
            if codigo in seen_codes:
                log(f"Aviso: Ciclo detectado para CODIGO={codigo}")
                return []
            seen_codes.add(codigo)
            exploded_codes.add(codigo)  # Rastrear códigos explodidos

            try:
                components = df[(df["Parent"] == codigo) & (df["AUXILIAR"].str.endswith("C"))]
                if components.empty:
                    return []
                result = []
                for _, row in components.iterrows():
                    comp_code = row["CODIGO"]
                    qty = row["Qtde_Formula"]
                    alerts = row["Alertas"] if nivel == max_levels else np.nan
                    new_row = {
                        "PCP_Codigo": parent_path[0],
                        "Nivel": nivel,
                        "Parent": codigo,
                        "Descr._Parent": description_map.get(codigo, codigo),
                        "CODIGO": comp_code,
                        "Descr._Componente": description_map.get(comp_code, comp_code),
                        "Qtde_Formula": qty,
                        "Alertas": alerts
                    }
                    result.append(new_row)
                    if comp_code not in exploded_codes and nivel >= dependency_map[comp_code]:
                        sub_rows = build_hierarchy(
                            df, comp_code, description_map, nivel + 1, parent_path, seen_codes.copy(), exploded_codes
                        )
                        result.extend(sub_rows)
                return result
            except Exception as e:
                raise ValueError(f"Erro ao construir hierarquia para codigo {codigo}, nivel {nivel}: {str(e)}")

        # Normalizar nomes de colunas
        df.columns = df.columns.str.strip()
        df = df.rename(columns=lambda x: x.strip())
        if "CÓDIGO" in df.columns:
            df = df.rename(columns={"CÓDIGO": "CODIGO"})
        if "CODIGO " in df.columns:
            df = df.rename(columns={"CODIGO ": "CODIGO"})
        if "Codigo" in df.columns:
            df = df.rename(columns={"Codigo": "CODIGO"})

        # Garantir que CODIGO e NIVEL sejam strings
        df["CODIGO"] = df["CODIGO"].str.strip().str.upper().fillna("")
        df["NIVEL"] = df["NIVEL"].str.strip().fillna("")
        df["AUXILIAR"] = df["AUXILIAR"].str.strip().str.upper().fillna("")

        # Remover duplicatas
        duplicates = df[df[["CODIGO", "Parent", "AUXILIAR"]].duplicated(keep=False)]
        if not duplicates.empty:
            log(f"Aviso: {len(duplicates)} duplicatas encontradas em CODIGO+Parent+AUXILIAR. Removendo duplicatas.")
            df = df.drop_duplicates(subset=["CODIGO", "Parent", "AUXILIAR"], keep="first")

        # Filtrar componentes
        df_components = df[df["AUXILIAR"].str.endswith("C")].copy()
        if df_components.empty:
            raise ValueError("Nenhum componente encontrado com AUXILIAR terminando em 'C'.")

        # Garantir que QUANTIDADE seja tratado corretamente
        df_components["QUANTIDADE"] = pd.to_numeric(df_components["QUANTIDADE"], errors="coerce")
        if df_components["QUANTIDADE"].isna().all():
            raise ValueError("Coluna QUANTIDADE contém apenas valores inválidos para componentes.")
        if df_components["QUANTIDADE"].isna().any():
            log(f"Aviso: {df_components['QUANTIDADE'].isna().sum()} valores inválidos em QUANTIDADE.")

        # Normalizar quantidades
        log("Normalizando quantidades...")
        df_components["Qtde_Formula"] = np.nan
        for parent in df_components["Parent"].unique():
            if pd.notna(parent):
                log(f"Processando Parent={parent}")
                df_components.loc[df_components["Parent"] == parent, "Qtde_Formula"] = normalize_qty(
                    df_components, parent
                ).reindex(df_components.index, fill_value=np.nan)

        # Gerar alertas
        log("Gerando alertas...")
        exploded_codes = set()  # Rastrear todos os códigos explodidos
        def check_alert(row, df, nivel_1_codes, exploded_codes, max_levels=10):
            nivel = None
            for i in range(1, max_levels + 1):
                nivel_col = f"Nivel_{i}"
                if nivel_col in row.index and pd.notna(row[nivel_col]):
                    nivel = int(row[nivel_col])
                    break
            if nivel is None:
                return f"ALERTA: Nível não encontrado para a linha"
            component_code = row[f"Componente_{nivel}"]
            if component_code not in exploded_codes and component_code not in nivel_1_codes:
                return f"ALERTA: Estrutura não encontrada para {component_code} (não explodido em nenhum nível)"
            return np.nan

        # Processar em lotes
        log("Construindo hierarquia em lotes...")
        result_rows = []
        for i in range(0, len(top_level), batch_size):
            batch_codes = top_level[i:i + batch_size]
            log(f"Processando lote {i // batch_size + 1} com {len(batch_codes)} códigos: {batch_codes}")
            hierarchical_data = []
            for codigo in batch_codes:
                hierarchical_data.extend(build_hierarchy(df_components, codigo, description_map, exploded_codes=exploded_codes))
            
            df_hierarchy = pd.DataFrame(hierarchical_data)
            if df_hierarchy.empty:
                log(f"Aviso: Nenhuma hierarquia gerada para o lote {i // batch_size + 1}.")
                continue

            # Exportar df_hierarchy para inspeção
            df_hierarchy.to_csv(f"df_hierarchy_batch_{i // batch_size + 1}.csv", index=False)
            log(f"Exportado df_hierarchy_batch_{i // batch_size + 1}.csv com {len(df_hierarchy)} linhas.")

            # Construir DataFrame final com múltiplas linhas por PCP_Codigo
            max_nivel = df_hierarchy["Nivel"].max()
            log(f"Nível máximo no lote {i // batch_size + 1}: {max_nivel}")
            batch_rows = []
            for pcp_codigo in df_hierarchy["PCP_Codigo"].unique():
                pcp_rows = df_hierarchy[df_hierarchy["PCP_Codigo"] == pcp_codigo]
                for _, row in pcp_rows.iterrows():
                    nivel = row["Nivel"]
                    new_row = {
                        "PCP_Codigo": pcp_codigo,
                        "PCP_Quantid.": np.nan,
                        f"Codigo_{nivel}": row["Parent"],
                        f"Descr._{nivel}": row["Descr._Parent"],
                        f"Componente_{nivel}": row["CODIGO"],
                        f"Descr. Comp._{nivel}": row["Descr._Componente"],
                        f"Nivel_{nivel}": nivel,
                        f"Qtde_Formula_{nivel}": row["Qtde_Formula"],
                        "Alertas": row["Alertas"]
                    }
                    batch_rows.append(new_row)
            
            result_rows.extend(batch_rows)

        if not result_rows:
            raise ValueError("Nenhum resultado gerado após processamento em lotes.")
        result_df = pd.DataFrame(result_rows)

        # Aplicar alertas após explosão
        result_df["Alertas"] = result_df.apply(lambda row: check_alert(row, df, nivel_1_codes, exploded_codes, max_levels), axis=1)

        # Selecionar e preencher colunas
        columns = ["PCP_Codigo", "PCP_Quantid."] + [
            col for nivel in range(1, max_levels + 1) for col in [
                f"Codigo_{nivel}",
                f"Descr._{nivel}",
                f"Componente_{nivel}",
                f"Descr. Comp._{nivel}",
                f"Nivel_{nivel}",
                f"Qtde_Formula_{nivel}"
            ]
        ] + ["Alertas"]
        columns = [col for col in columns if col in result_df.columns or col in columns]
        result_df = result_df.reindex(columns=columns)

        # Log final do tamanho da hierarquia
        log(f"Hierarquia final gerada com {len(result_df)} linhas em NDC_Formulas_Prov.xlsx")
        return result_df
    except Exception as e:
        log(f"Erro detalhado no processamento: {str(e)}")
        log("Stack trace:")
        log(traceback.format_exc())
        return None

class App:
    def __init__(self, root):
        self.root = root
        self.root.title("Transformador de Fórmulas TOTVS")
        self.root.geometry("600x400")

        # Variáveis para armazenar caminhos dos arquivos
        self.input_file = tk.StringVar()
        self.output_file = tk.StringVar()

        # Interface
        tk.Label(root, text="Transformador de Fórmulas TOTVS", font=("Arial", 14)).pack(pady=10)

        # Seleção de arquivo de entrada
        tk.Label(root, text="Arquivo de Entrada:").pack(anchor="w", padx=10)
        tk.Entry(root, textvariable=self.input_file, width=50, state='readonly').pack(padx=10, pady=5)
        tk.Button(root, text="Selecionar Entrada", command=self.select_input).pack(pady=5)

        # Seleção de arquivo de saída
        tk.Label(root, text="Arquivo de Saída:").pack(anchor="w", padx=10)
        tk.Entry(root, textvariable=self.output_file, width=50, state='readonly').pack(padx=10, pady=5)
        tk.Button(root, text="Selecionar Saída", command=self.select_output).pack(pady=5)

        # Botão para processar
        tk.Button(root, text="Processar", command=self.process, font=("Arial", 12)).pack(pady=10)

        # Área de log
        tk.Label(root, text="Log de Processamento:").pack(anchor="w", padx=10)
        self.log_area = scrolledtext.ScrolledText(root, height=10, width=60, state='disabled')
        self.log_area.pack(padx=10, pady=5)

        # Redirecionar print para a área de log
        sys.stdout = TextRedirector(self.log_area)

    def select_input(self):
        file_path = filedialog.askopenfilename(
            title="Selecione o arquivo Excel de origem",
            filetypes=[("Arquivos Excel", "*.xlsx *.xls")]
        )
        if file_path:
            self.input_file.set(file_path)
            print(f"Arquivo de entrada selecionado: {file_path}")

    def select_output(self):
        file_path = filedialog.asksaveasfilename(
            title="Salvar arquivo de saída",
            defaultextension=".xlsx",
            filetypes=[("Arquivos Excel", "*.xlsx")]
        )
        if file_path:
            self.output_file.set(file_path)
            print(f"Arquivo de saída selecionado: {file_path}")

    def process(self):
        input_file = self.input_file.get()
        output_file = self.output_file.get()

        if not input_file:
            messagebox.showerror("Erro", "Selecione um arquivo de entrada.")
            return
        if not output_file:
            messagebox.showerror("Erro", "Selecione um local para o arquivo de saída.")
            return

        try:
            print(f"Lendo Totvs_Formulas de: {input_file}")
            df_input = pd.read_excel(input_file, sheet_name="Totvs_Formulas")
            print(f"Lendo Tabela Comercial de: {input_file}")
            df_comercial = pd.read_excel(input_file, sheet_name="Tabela Comercial")
            if "Nivel_1" not in df_comercial.columns:
                raise ValueError("Coluna 'Nivel_1' não encontrada na planilha Tabela Comercial.")
            nivel_1_codes = df_comercial["Nivel_1"].dropna().astype(str).str.strip().str.upper().tolist()
            if not nivel_1_codes:
                raise ValueError("Nenhum código encontrado na coluna Nivel_1.")
        except Exception as e:
            print(f"Erro ao ler as planilhas: {str(e)}")
            messagebox.showerror("Erro", f"Falha ao ler as planilhas: {str(e)}")
            return

        result_df = processar_formulas(df_input, nivel_1_codes, batch_size=10, max_levels=10, log_widget=TextRedirector(self.log_area))
        if result_df is None:
            print("Falha no processamento. Verifique os erros acima.")
            messagebox.showerror("Erro", "Falha no processamento. Verifique o log.")
            return

        try:
            result_df.to_excel(output_file, index=False)
            print(f"Arquivo salvo com sucesso em: {output_file}")
            print("Copie os dados para a planilha NDC_Formulacao no Excel.")
            messagebox.showinfo("Sucesso", f"Processamento concluído! Arquivo salvo em: {output_file}")
        except Exception as e:
            print(f"Erro ao salvar o arquivo: {str(e)}")
            messagebox.showerror("Erro", f"Erro ao salvar o arquivo: {str(e)}")

def main():
    root = tk.Tk()
    app = App(root)
    root.mainloop()

if __name__ == "__main__":
    main()